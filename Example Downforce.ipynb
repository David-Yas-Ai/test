{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ce9b0d-e621-4ae0-9f8e-23e68a5679b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 8238.9639 - mae: 58.9845 - val_loss: 8342.5908 - val_mae: 52.0096\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9392.1895 - mae: 63.0446 - val_loss: 8324.2334 - val_mae: 51.8822\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8304.8018 - mae: 59.5336 - val_loss: 8306.6406 - val_mae: 51.7582\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8481.1865 - mae: 59.5397 - val_loss: 8288.4463 - val_mae: 51.6349\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8601.9551 - mae: 60.3728 - val_loss: 8269.9199 - val_mae: 51.5101\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8159.4404 - mae: 59.2152 - val_loss: 8251.6445 - val_mae: 51.3805\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9334.5967 - mae: 63.1047 - val_loss: 8232.9355 - val_mae: 51.2455\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9418.5020 - mae: 62.3058 - val_loss: 8213.1709 - val_mae: 51.1045\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9608.1914 - mae: 64.6907 - val_loss: 8194.1611 - val_mae: 50.9607\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7978.2627 - mae: 58.6921 - val_loss: 8175.2500 - val_mae: 50.8106\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7232.0063 - mae: 54.1646 - val_loss: 8152.7944 - val_mae: 50.6385\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8327.4121 - mae: 59.6323 - val_loss: 8126.2905 - val_mae: 50.4468\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8318.9629 - mae: 59.7419 - val_loss: 8097.1865 - val_mae: 50.2602\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8985.7207 - mae: 62.0254 - val_loss: 8067.0322 - val_mae: 50.0803\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8574.0225 - mae: 59.9432 - val_loss: 8036.0195 - val_mae: 49.8906\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8563.9414 - mae: 60.2081 - val_loss: 8002.5522 - val_mae: 49.6916\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9112.0820 - mae: 60.9197 - val_loss: 7965.3516 - val_mae: 49.4761\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7699.2549 - mae: 57.7840 - val_loss: 7925.8726 - val_mae: 49.2419\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7655.5366 - mae: 54.4211 - val_loss: 7882.4150 - val_mae: 48.9832\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8548.0508 - mae: 58.5297 - val_loss: 7835.3423 - val_mae: 48.7003\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8770.9688 - mae: 60.7562 - val_loss: 7784.8032 - val_mae: 48.3994\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7265.4292 - mae: 55.1606 - val_loss: 7731.0576 - val_mae: 48.0990\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7463.5693 - mae: 56.4624 - val_loss: 7670.2822 - val_mae: 47.7914\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7444.9077 - mae: 54.5643 - val_loss: 7601.0132 - val_mae: 47.4581\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7433.9429 - mae: 54.1156 - val_loss: 7525.7720 - val_mae: 47.0983\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9052.7793 - mae: 60.5565 - val_loss: 7447.8516 - val_mae: 46.7148\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7227.1606 - mae: 53.7708 - val_loss: 7368.8149 - val_mae: 46.3227\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8214.6406 - mae: 56.8025 - val_loss: 7282.6406 - val_mae: 45.9515\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7589.0542 - mae: 54.5480 - val_loss: 7187.4751 - val_mae: 45.5719\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8224.4951 - mae: 58.2783 - val_loss: 7085.0103 - val_mae: 45.1549\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7459.8979 - mae: 55.9008 - val_loss: 6974.2671 - val_mae: 44.6985\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6207.1226 - mae: 49.1261 - val_loss: 6853.7373 - val_mae: 44.1983\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6929.8550 - mae: 52.0416 - val_loss: 6722.3477 - val_mae: 43.6549\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7829.8818 - mae: 54.1760 - val_loss: 6586.0010 - val_mae: 43.1441\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6935.3022 - mae: 53.7575 - val_loss: 6448.3276 - val_mae: 42.7121\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6718.0898 - mae: 49.5380 - val_loss: 6309.8052 - val_mae: 42.2696\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7579.4004 - mae: 54.9217 - val_loss: 6162.8369 - val_mae: 41.7925\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6625.1958 - mae: 50.2392 - val_loss: 6006.9009 - val_mae: 41.2760\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6416.2061 - mae: 49.6113 - val_loss: 5838.0542 - val_mae: 40.7059\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6123.6260 - mae: 48.6591 - val_loss: 5660.2900 - val_mae: 40.0954\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7281.2715 - mae: 52.6794 - val_loss: 5470.0752 - val_mae: 39.4349\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6163.6143 - mae: 49.1621 - val_loss: 5279.5244 - val_mae: 38.7594\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5791.8472 - mae: 46.4455 - val_loss: 5080.1362 - val_mae: 38.0282\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6201.3765 - mae: 48.6321 - val_loss: 4878.7012 - val_mae: 37.2801\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6086.0156 - mae: 48.3632 - val_loss: 4684.2979 - val_mae: 36.5425\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4516.1772 - mae: 42.4250 - val_loss: 4498.8672 - val_mae: 35.8225\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4742.4858 - mae: 43.1118 - val_loss: 4312.0400 - val_mae: 35.0678\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5444.5938 - mae: 45.8946 - val_loss: 4116.1851 - val_mae: 34.2428\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4310.3823 - mae: 41.6383 - val_loss: 3923.4233 - val_mae: 33.4153\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4487.0562 - mae: 41.7149 - val_loss: 3717.1040 - val_mae: 32.5074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 793.3596 - mae: 20.7878\n",
      "\n",
      "Test Loss: 793.3596, Test MAE: 20.7878\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "file_path = r\"C:/Users/david/OneDrive/Documents/YasAi/Schulung KI/Beispiele/wing_downforce_drag_optimization_dataset_with_angle.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Split data into 70% training and 30% temporary (test + validation)\n",
    "train_data, temp_data = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 3: Split the temporary data into 20% test and 10% validation\n",
    "test_data, validation_data = train_test_split(temp_data, test_size=1/3, random_state=42)\n",
    "\n",
    "# Step 4: Separate the features (X) and target (y)\n",
    "# Assuming \"Downforce (N)\" is the target column. Adjust as needed.\n",
    "X_train = train_data.drop(columns=[\"Downforce (N)\"])  # Features\n",
    "y_train = train_data[\"Downforce (N)\"]  # Target\n",
    "\n",
    "X_test = test_data.drop(columns=[\"Downforce (N)\"])\n",
    "y_test = test_data[\"Downforce (N)\"]\n",
    "\n",
    "X_val = validation_data.drop(columns=[\"Downforce (N)\"])\n",
    "y_val = validation_data[\"Downforce (N)\"]\n",
    "\n",
    "# Step 5: Standardize the features (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Step 6: Define the Keras model with an explicit Input layer\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),  # Explicit Input layer\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output layer for regression (predicting downforce)\n",
    "])\n",
    "\n",
    "# Step 7: Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])  # MSE for regression, MAE as additional metric\n",
    "\n",
    "# Step 8: Train the model\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=50,  # Adjust number of epochs as needed\n",
    "    batch_size=32,  # Adjust batch size as needed\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Step 9: Evaluate the model on the test data\n",
    "test_loss, test_mae = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb96dab-1066-4ef2-ba03-24355e4553ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
